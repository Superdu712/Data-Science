---
title: "HW5_490_12"
output: html_document
date: "`r format(Sys.time(), '%B %d, %Y')`"
---


## Part 1
***
For this problem we will start with a simulation in order to find out how large n needs
to be for the binomial distribution to be approximated by the normal
distribution. 

***

### Exercises
We will take m samples from the binomial distribution for some n and p.

**1.** Let's let p=1/2, use the rbinom function to generate the sample of size m. Add normal curves to all of the plots. Use 3 values for n, 10, 30, and 50. Display the histograms as well as your code below. ***(4 pts)***  

```{r}
m <- 200
n <- c(10,30,50)
p <- 1/2

b1 <- rbinom(m,10,p)
b2 <- rbinom(m,30,p)
b3 <- rbinom(m,50,p)
```

```{r}
hist(b1,freq=F)
curve(dnorm(x,mean=mean(b1), sd=sd(b1)),add=T)

hist(b2,freq=F)
curve(dnorm(x,mean=mean(b2), sd=sd(b2)),add=T)

hist(b3,freq=F)
curve(dnorm(x,mean=mean(b3), sd=sd(b3)),add=T)
```

**1b.** Now use the techniques described in class to improve graphs. Explain each step you choose including why you are making the change. You might consider creating density plots, changing color, axes, labeling, legend, and others for example. ***(3 pts)***  

 
```{r}
hist(b1,freq=F, ylim=c(0,0.3), xlab="rbinom(m=200, n=10, p=0.5)", main="Probability Density", col="gray99")
# specify y-axis limit, since sometimes the graph went off the limit. Label x-axis and title, change graph color.
curve(dnorm(x,mean=mean(b1), sd=sd(b1)),add=T, lwd=2, col="midnightblue")
# make normal curve thicker by specifying line width, change curve color.
lines(density(b1), lty=3, lwd=2.5, col="violetred1")
# create a density line, specify line type as dotted line, adjust line width to make it slightly thicker than normal curve, change line color.
legend("topright", c("Normal Curve","Density Curve"), cex=0.8, col=c("midnightblue","violetred1"), lty=c(1,3), lwd=c(2,2.5), bty="n") # add legend to the top right corner, name it respectively, use the same line colors, line types, and line width, make the legend no border.
```

Do the same improvements for the rest two graphs.

```{r}
hist(b2,freq=F, ylim=c(0,0.18), xlab="rbinom(m=200, n=30, p=0.5)", main="Probability Density",col="gray99")
curve(dnorm(x,mean=mean(b2), sd=sd(b2)),add=T, lwd=2, col="midnightblue")
lines(density(b2), lty=3, lwd=2.5, col="violetred1")
legend("topright", c("Normal Curve","Density Curve"), cex=0.8, col=c("midnightblue","violetred1"), lty=c(1,3), lwd=c(2,2.5), bty="n")

hist(b3,freq=F, ylim=c(0,0.15), xlab="rbinom(m=200, n=50, p=0.5)", main="Probability Density", col="gray99")
curve(dnorm(x,mean=mean(b3), sd=sd(b3)),add=T, lwd=2, col="midnightblue")
lines(density(b3), lty=3, lwd=2.5, col="violetred1")
legend("topright", c("Normal Curve","Density Curve"), cex=0.8, col=c("midnightblue","violetred1"), lty=c(1,3), lwd=c(2,2.5), bty="n")
```

**2.** Why do you think the Data Life Cycle is crucial to understanding the opportunities and challenges of making the most of digital data? Give two examples. ***(2 pts)***  

```
1). Digital data are enormous and dispersed, so it is challenging to define criteria for narrow down data size, so as to not lose out any valuable information.
For example, it is easy for us to know customer preference data sourced from the information they share on key social media channels. But the challenge is to tap the non-social media users who might also be an important customer segment.
The data acquisition step can help to understand what are the data sources for these customers.
2). Data management lifecycle enable reuse and repurposing of the data, and to allow for the eventual long-term preservation and management of the data.
For example, rsesearch data usually have a longer timespan than the research project creating them. After the research has been completed, the research team deposits the data in an archive for sharing purposes. 
The data are processed and documented both during research and in the archiving stage. Duplicated effort and information loss will be avoided if different stages of the data life cycle are planned well before data collection.
```   
***

## Part 2

***
San Francisco Housing Data

***

Before loading the data, remove all the values in workspace.
```{r}
rm(list = ls())
```

Load the data into R.

```{r}
load(url("http://www.stanford.edu/~vcs/StatData/SFHousing.rda"))
```

**3.**  What is the name and class of each object you have loaded into your workspace?  ***(2 pts)***  

```{r}
objects()
class(cities)
class(housing)
```

What are the names of the vectors in housing?

```{r}
names(housing)
```

How many observations are in housing?

```{r}
dim(housing)
```

```
There are 281,506 observations.
```

Explore the data using the summary function. Describe in words two problems that you see with the data.
 
```{r}
summary(housing)
```

```
1). There are 23316 NA's in long, lat, quality, match, and 21687 NA's in lsqft. Almost 10% of the data are missing for these variables. Thus, we can see that these data does not add much value to the housing data frame.
2). The minimum year is 0 and the maximum year is 3894, clearly year in housing data is miscoded.
```

**5.** We will work the houses in Albany, Berkeley, Piedmont, and Emeryville only. 
Subset the data frame so that we have only houses in these cities and keep only the variables city, zip, price, br, bsqft, and year. 
Call this new data frame BerkArea. This data frame should have 4059 observations and 6 variables. ***(2 pts)***  

```{r}
someCities <- c("Albany", "Berkeley", "Piedmont", "Emeryville")
BerkArea <- housing[housing$city %in% someCities, c("city", "zip", "price", "br", "bsqft", "year")]
dim(BerkArea)
```

**6.** We are interested in making plots of price and size of house, but before we do this we will further subset the data frame to remove the unusually large values.
Use the quantile function to determine the 99th percentile of price and bsqft and eliminate all of those houses that are above either of these 99th percentiles
Call this new data frame BerkArea, as well. It should have 3999 observations. ***(2 pts)***  

```{r}
quantprice <- quantile(BerkArea$price, probs=0.99, na.rm=TRUE)
quantbsqft <- quantile(BerkArea$bsqft, probs=0.99, na.rm=TRUE)
BerkArea <- BerkArea[BerkArea$price <= quantprice & BerkArea$bsqft <= quantbsqft,]
```

**7.** Create a new vector that is called pricepsqft by dividing the sale price by the square footage. Add this new variable to the data frame. ***(2 pts)***  

```{r}
BerkArea$pricepsqft <- BerkArea$price/BerkArea$bsqft
head(BerkArea)
```

**8.** Create a vector called br5 that is the number of bedrooms in the house, except if this number is greater than 5, it is set to 5. That is, if a house has 5 or more bedrooms then br5 will be 5. Otherwise it will be the number of bedrooms. ***(2 pts)***  

```{r}
br5 <- BerkArea$br
br5[BerkArea$br >= 5] <- 5
```

**9.** Use the rainbow function to create a vector of 5 colors, call this vector rCols. When you call this function, set the alpha argument to 0.25 (we will describe what this does later)
Create a vector called brCols of 4059 colors where each element's color corresponds to the number of bedrooms in the br5.
For example, if the element in br5 is 3 then the color will be the third color in rCols. ***(4 pts 2 + 2 - see below)***  

```{r}
rCols <- rainbow(5, alpha = 0.25)
brCols <- rCols[br5]
```

***(2 pts)***  
We are now ready to make a plot.
Try out the following code:

```{r}
plot(pricepsqft ~ bsqft, data = BerkArea,
     main = "Housing prices in the Berkeley Area",
     xlab = "Size of house (square ft)",
     ylab = "Price per square foot",
     col = brCols, pch = 19, cex = 0.5)
legend(legend = 1:5, fill = rCols, "topright")
```

What interesting features do you see that you didn't know before making this plot? ***(2 pts)***   

```
1). Most of the houses are between the size of 500 to 2000 square feet.
2). As the size of house increases, the number of bedrooms tend to increases. 
3). As the size of house increases, price per square foot of the house tend to decreases. 
4). Some one or two bedrooom houses also have low unit price like that of houses with more bedrooms, so there is not an obvious relationship between number of bedrooms and price per sqaure foot.
```

Replicate the boxplots presented in class, with the boxplots sorted by median housing price (slide 45 of the lecture notes). ***(2 pts)***  

```{r}
bymedian <-with(BerkArea, reorder(factor(BerkArea$city), price, median)) 
boxplot(BerkArea$price ~ bymedian, las=2, main="Cities ordered by median housing price")
```
